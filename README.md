# ğŸ­ Real-Time Facial Emotion Detection Using Deep Learning

This project detects human emotions in real-time using facial expressions captured through a webcam.  
It was built entirely with **TensorFlow/Keras, OpenCV, and Streamlit**, trained on the **Two datasets**, and deploys a **custom CNN model** for classification â€” not transfer learning.

#### Datasets:
1. https://www.kaggle.com/datasets/jonathanoheix/face-expression-recognition-dataset
2. https://www.kaggle.com/datasets/msambare/fer2013
---

## ğŸ§  Overview

Facial Emotion Recognition helps computers understand human emotions by analyzing facial patterns.  
Our model classifies six emotions:

> **Angry | Fear | Happy | Neutral | Sad | Surprise**

The system detects faces from a live webcam feed, preprocesses them into 48Ã—48 grayscale images, and predicts the emotion in real-time using a CNN model trained from scratch.

---

## ğŸ§© Key Features

- Custom **Convolutional Neural Network (CNN)** â€” no pre-trained model. (grayscale, 48Ã—48 pixels) 
- Real-time **face detection** with OpenCV.  
- **Streamlit frontend** with live webcam display.  
- Evaluation metrics â€” accuracy, loss curves, confusion matrix, classification report.  
- Lightweight and completely local â€” no internet APIs required.

---

## ğŸ—‚ï¸ Folder Structure
Emotion-Detection/
â”‚
â”œâ”€â”€ data
â”‚ â”œâ”€â”€ train
â”‚ â”œâ”€â”€ test
â”‚
â”œâ”€â”€ model/ 
â”‚ â”œâ”€â”€ emotion_model.h5
â”‚
â”œâ”€â”€ confusion_matrix.png
â”œâ”€â”€ training_plot.png
â”‚
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ train_model.py 
â”‚
â”œâ”€â”€ main.py 
â”œâ”€â”€ requirements.txt 
â””â”€â”€ README.md
 
---

## âš™ï¸ Setup Instructions

### 1. Install Requirements
```bash
pip install -r requirements.txt
```
### 2. Train the Model
```bash
python scripts/train_model.py
```
#### This script:
Builds a CNN model (Conv2D, MaxPooling2D, Dense, Dropout)
Saves the trained model as emotion_model.h5
#### Generates:
- training_plot.png â€“ accuracy & loss curves
- confusion_matrix.png â€“ class performance visualization

### 3. Run the Real-Time App
```
streamlit run main.py
```
Then open the local URL shown in your terminal (usually http://localhost:8501).

## ğŸ§® Model Architecture
| Layer                     | Output Shape | Description                         |
| ------------------------- | ------------ | ----------------------------------- |
| Conv2D (32 filters, 3Ã—3)  | 46Ã—46Ã—32     | Detects edges and corners           |
| MaxPooling2D (2Ã—2)        | 23Ã—23Ã—32     | Reduces spatial size                |
| Conv2D (64 filters, 3Ã—3)  | 21Ã—21Ã—64     | Detects facial parts                |
| MaxPooling2D (2Ã—2)        | 10Ã—10Ã—64     | Keeps key patterns                  |
| Conv2D (128 filters, 3Ã—3) | 8Ã—8Ã—128      | Learns full expressions             |
| MaxPooling2D (2Ã—2)        | 4Ã—4Ã—128      | Compresses patterns                 |
| Flatten                   | â€”            | Converts to 1D                      |
| Dense (128) + ReLU        | â€”            | Learns emotion patterns             |
| Dropout (0.5)             | â€”            | Prevents overfitting                |
| Dense (6, Softmax)        | â€”            | Output probabilities for 6 emotions |

Optimizer: Adam (lr=1e-3)
Loss: Categorical Crossentropy
Metrics: Accuracy

## ğŸ“ˆ Training Results
Accuracy curves and confusion matrix are saved under /model/
Example outputs:
- training_plot.png â†’ model accuracy & loss over epochs
- confusion_matrix.png â†’ visual of predicted vs true labels

## ğŸ’» Real-Time Detection (main.py)
- Uses OpenCV to capture webcam video
- Detects faces using Haarcascade classifier
- Crops and preprocesses each face (48Ã—48 grayscale)
- Predicts emotion via trained CNN
- Displays emotion label and confidence on-screen
- Streamlit provides a dark, minimal UI for demo purposes

## ğŸ§¾ Tools & Libraries
| Category              | Tools Used          |
| --------------------- | ------------------- |
| Programming Language  | Python 3.10+        |
| Deep Learning         | TensorFlow / Keras  |
| Image Processing      | OpenCV              |
| Visualization         | Matplotlib, Seaborn |
| Frontend / Deployment | Streamlit           |
| Evaluation            | scikit-learn        |

## ğŸ§± System Requirements
| Component | Minimum                        | Recommended           |
| --------- | ------------------------------ | --------------------- |
| CPU       | Intel i5 / AMD equivalent      | i7+                   |
| GPU       | â€”                              | NVIDIA (CUDA 2â€“4 GB+) |
| RAM       | 8 GB                           | 16 GB                 |
| OS        | Windows 10/11, Linux, or macOS | â€”                     |
| Python    | 3.7+                           | 3.10+                 |

## ğŸš€ Future Enhancements
- Integrate with transfer learning (e.g., MobileNetV2) for higher accuracy
- Add multi-face detection and batch prediction
- Build dashboard view to analyze emotions over time
- Explore multimodal emotion recognition (audio + facial)

## ğŸ“š References
1. OpenCV â€“ Face detection using Haarcascade
2. TensorFlow/Keras Docs â€“ CNN implementation examples
3. Analytics Vidhya / Medium â€“ Emotion Recognition tutorials

## ğŸ‘¤ Authors
Saksham Kumar
Shreeya Barahpuriya
Department of Computer Applications â€” BCA V Semester

|| â€œBy enabling computers to understand non-verbal cues, this system enhances human-computer interaction and contributes toward more adaptive, intelligent AI systems.â€ ||
